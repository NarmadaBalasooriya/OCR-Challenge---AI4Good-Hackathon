{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI4Good_hack.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoiCRQ-BoDO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir train_images\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def img_compute(img):\n",
        "\t\n",
        "\t#img = cv2.resize(img, (128,128), 3)\n",
        "\t#print(img.shape)\n",
        "\t#img = np.reshape(img, (128, 128), 1)\n",
        "\timg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "\tgray = cv2.threshold(img, 0, 225, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "\t#kernel = np.ones((2,2),np.uint8)\n",
        "\t#gray = cv2.erode(gray,kernel,iterations = 1)\n",
        "\n",
        "\treturn gray\n",
        "\n",
        "n=0\n",
        "\n",
        "for img_file in glob.glob('./AI4Good---Meza-OCR-Challenge/cell_images/training_set/*.jpg'):\n",
        "  im = cv2.imread(img_file)\n",
        "  im_n = img_compute(im)\n",
        "\t#im_n = im_n.flatten()\n",
        "  n = n+1\n",
        "  file_n = img_file\n",
        "  file_n = file_n.split(\"training_set/\", 1)\n",
        "  file_n = file_n[1]\n",
        "  #print('working here ', file_n)\n",
        "  cv2.imwrite(os.path.join('./train_images/', file_n), im_n)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCDY90PbugnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r utils.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QLjfyYaJ2iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! git clone https://github.com/Charitable-Analytics-International/AI4Good---Meza-OCR-Challenge.git\n",
        "#!sudo apt install tesseract-ocr\n",
        "#!pip install pytesseract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk6jp9nhuqtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import datetime\n",
        "import logging\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxsnlHaJsV25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATADIR = '/content/AI4Good---Meza-OCR-Challenge/cell_images/training_set_values.txt'\n",
        "VALID_DIR = '/content/AI4Good---Meza-OCR-Challenge/cell_images/validation_set_values.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G7htHwDl7rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def load_labels(file):\n",
        "    labels = list(open(file).readlines())\n",
        "    labels = [s.strip() for s in labels[1:]]\n",
        "    labels = [s.split(';') for s in labels]\n",
        "\n",
        "    labels_dict = dict(labels)\n",
        "\n",
        "    labels = np.asarray(labels, dtype=str)\n",
        "    labels = labels[:, 1]\n",
        "\n",
        "    return labels, labels_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cplbe8LEsd3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l, ld = load_labels(DATADIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVMhiVu4fc6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process(k,img):\n",
        "        thresh = cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU\n",
        "        low = 80\n",
        "        proc = cv2.cvtColor(cv2.medianBlur(cv2.threshold(cv2.cvtColor(cv2.resize(img, (0, 0), fx=5, fy=5), cv2.COLOR_BGR2GRAY), low, 255, thresh)[1], 3), cv2.COLOR_GRAY2RGB)\n",
        "        data = image_to_string(Image.fromarray(proc), lang='eng', config='--psm 6').replace('Rina','Ring')\n",
        "        return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcWw_yXNuUZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_img_path(images_path):\n",
        "    tmp = os.listdir(images_path)\n",
        "    tmp.sort(key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "    file_names = [images_path + s for s in tmp]\n",
        "\n",
        "    file_names = np.asarray(file_names)\n",
        "\n",
        "    return file_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwMS0MRVuY8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_names = load_img_path('./train_images/')\n",
        "#valid_names = load_img_path('/content/AI4Good---Meza-OCR-Challenge/cell_images/validation_set/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHvy0c7Yuwt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4270c2eb-e075-48e7-ee49-83ae428903c8"
      },
      "source": [
        "file_names"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['./train_images/1.jpg', './train_images/2.jpg',\n",
              "       './train_images/3.jpg', ..., './train_images/7495.jpg',\n",
              "       './train_images/7496.jpg', './train_images/7497.jpg'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE79bbDvuTZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_val(X, y, train_size):\n",
        "    \"\"\"Split dataset for training and validation.\n",
        "\n",
        "    Args:\n",
        "        X: A 1-D numpy array containing pathes of images.\n",
        "        y: A 1-D numpy array containing labels.\n",
        "        train_size: Size of training data to split.\n",
        "    Returns:\n",
        "        1-D numpy array having the same definition with X and y.\n",
        "    \"\"\"\n",
        "\n",
        "    total_size = len(X)\n",
        "    # shuffle data\n",
        "    shuffle_indices = np.random.permutation(np.arange(total_size))\n",
        "    X = X[shuffle_indices]\n",
        "    y = y[shuffle_indices]\n",
        "\n",
        "    # split training data\n",
        "    train_indices = np.random.choice(total_size, train_size, replace=False)\n",
        "    X_train = X[train_indices]\n",
        "    y_train = y[train_indices]\n",
        "\n",
        "    # split validation data\n",
        "    val_indices = [i for i in range(total_size) if i not in train_indices]\n",
        "    X_val = X[val_indices]\n",
        "    y_val = y[val_indices]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3__2Jw_3uvfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_names, l, valid_names, v = split_train_val(file_names, l, 6000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frdse3PIvyoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_to_file(data, file_to_output='./X_train.txt'):\n",
        "    \"\"\"Write X_train/y_train/X_val/y_val/X_infer to file for further\n",
        "       processing (e.g. make input queue of tensorflow).\n",
        "    Args:\n",
        "        data: A 1-D numpy array, e.g, X_train/y_train/X_val/y_val/X_infer.\n",
        "        file_to_output: A file to store data.\n",
        "    \"\"\"\n",
        "    # with open('X_train.csv','a') as f_handle:\n",
        "    #     np.savetxt(f_handle, X_train, fmt='%s', delimiter=\",\")\n",
        "\n",
        "    with open(file_to_output, 'w') as f:\n",
        "        for item in data.tolist():\n",
        "            f.write(item + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC-glmFOwEpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write_to_file(file_names)\n",
        "write_to_file(valid_names, file_to_output='./X_val.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQITBqhIw_Dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write_to_file(l, file_to_output='./y_train.txt')\n",
        "write_to_file(v, file_to_output='./y_val.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK-ODVFDzpil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cp_file(imgs_list_para, labels_list_para, dst_para):\n",
        "    for i in range(imgs_list_para.shape[0]):\n",
        "        file_path = imgs_list_para[i]\n",
        "\n",
        "        filename = os.path.basename(file_path)\n",
        "        fn = filename.split('.')[0]\n",
        "        ext = filename.split('.')[1]\n",
        "\n",
        "        dest_filename = dst_para + fn + '_' + labels_list_para[i] + '.' + ext\n",
        "\n",
        "\n",
        "        shutil.copyfile(file_path, dest_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLOfGRCVw4ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "921DyOknxfdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV7f6bdEz5TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir train\n",
        "!mkdir val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S7c432s0Ct1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp_file(file_names, l, './train/')\n",
        "cp_file(valid_names, v, './val/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jhj5Gii1PCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(file_to_read):\n",
        "    \"\"\"Load X_train/y_train/X_val/y_val/X_infer for further\n",
        "       processing (e.g. make input queue of tensorflow).\n",
        "    Args:\n",
        "        file_to_read:\n",
        "    Returns:\n",
        "        X_train/y_train/X_val/y_val/X_infer.\n",
        "    \"\"\"\n",
        "\n",
        "    data = np.recfromtxt(file_to_read)\n",
        "    data = np.asarray(data)\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CIyoLdshq65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Vb7hqMv_Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r utils.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kM7iU9T5zET",
        "colab_type": "code",
        "outputId": "8b40d771-a79a-4484-e3cb-2596646b01a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1233
        }
      },
      "source": [
        "!python ./main.py --train_dir=./train/ \\\n",
        "  --val_dir=./val/ \\\n",
        "  --image_height=128 \\\n",
        "  --image_width=128 \\\n",
        "  --image_channel=1 \\\n",
        "  --out_channels=64 \\\n",
        "  --num_hidden=128 \\\n",
        "  --batch_size=128 \\\n",
        "  --log_dir=./log/train \\\n",
        "  --num_gpus=1 \\\n",
        "  --mode=train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "\n",
            "feature_h: 8, feature_w: 8\n",
            "lstm input shape: [128, 8, 512]\n",
            "WARNING:tensorflow:From /content/cnn_lstm_otc_ocr.py:68: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/cnn_lstm_otc_ocr.py:77: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/cnn_lstm_otc_ocr.py:87: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "loading train data\n",
            "size:  6000\n",
            "loading validation data\n",
            "size: 1497\n",
            "\n",
            "2019-06-09 14:59:33.515366: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-06-09 14:59:33.515589: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x247e3c0 executing computations on platform Host. Devices:\n",
            "2019-06-09 14:59:33.515623: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-06-09 14:59:33.680181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-09 14:59:33.680670: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x247dce0 executing computations on platform CUDA. Devices:\n",
            "2019-06-09 14:59:33.680699: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-06-09 14:59:33.681053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-06-09 14:59:33.681076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-06-09 14:59:34.118371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-06-09 14:59:34.118434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-06-09 14:59:34.118446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-06-09 14:59:34.118770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "=============================begin training=============================\n",
            "2019-06-09 14:59:34.799075: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "6/9 14:59:40 Epoch 1/1000, accuracy = 0.009,avg_train_cost = 17.527, lastbatch_err = 13.785, time = 6.105,lr=0.00100000\n",
            "6/9 15:1:38 Epoch 11/1000, accuracy = 0.531,avg_train_cost = 1.672, lastbatch_err = 2.135, time = 11.377,lr=0.00100000\n",
            "6/9 15:3:37 Epoch 22/1000, accuracy = 0.663,avg_train_cost = 0.447, lastbatch_err = 1.462, time = 10.040,lr=0.00100000\n",
            "6/9 15:5:36 Epoch 33/1000, accuracy = 0.667,avg_train_cost = 0.176, lastbatch_err = 1.480, time = 8.621,lr=0.00100000\n",
            "6/9 15:7:35 Epoch 44/1000, accuracy = 0.665,avg_train_cost = 0.102, lastbatch_err = 1.669, time = 7.190,lr=0.00100000\n",
            "6/9 15:9:34 Epoch 55/1000, accuracy = 0.669,avg_train_cost = 0.087, lastbatch_err = 1.679, time = 5.798,lr=0.00100000\n",
            "6/9 15:11:33 Epoch 66/1000, accuracy = 0.679,avg_train_cost = 0.050, lastbatch_err = 1.794, time = 4.368,lr=0.00100000\n",
            "6/9 15:13:32 Epoch 77/1000, accuracy = 0.656,avg_train_cost = 0.172, lastbatch_err = 1.676, time = 3.010,lr=0.00100000\n",
            "6/9 15:15:31 Epoch 87/1000, accuracy = 0.685,avg_train_cost = 0.035, lastbatch_err = 1.716, time = 12.350,lr=0.00100000\n",
            "6/9 15:17:30 Epoch 98/1000, accuracy = 0.681,avg_train_cost = 0.073, lastbatch_err = 1.953, time = 10.949,lr=0.00100000\n",
            "6/9 15:19:29 Epoch 109/1000, accuracy = 0.677,avg_train_cost = 0.040, lastbatch_err = 1.714, time = 9.568,lr=0.00100000\n",
            "6/9 15:21:28 Epoch 120/1000, accuracy = 0.694,avg_train_cost = 0.033, lastbatch_err = 1.875, time = 8.166,lr=0.00100000\n",
            "6/9 15:23:27 Epoch 131/1000, accuracy = 0.702,avg_train_cost = 0.041, lastbatch_err = 2.070, time = 6.757,lr=0.00100000\n",
            "6/9 15:25:26 Epoch 142/1000, accuracy = 0.701,avg_train_cost = 0.024, lastbatch_err = 1.727, time = 5.384,lr=0.00100000\n",
            "6/9 15:27:24 Epoch 153/1000, accuracy = 0.673,avg_train_cost = 0.081, lastbatch_err = 1.723, time = 3.956,lr=0.00100000\n",
            "6/9 15:29:23 Epoch 164/1000, accuracy = 0.697,avg_train_cost = 0.021, lastbatch_err = 1.957, time = 2.554,lr=0.00100000\n",
            "6/9 15:31:22 Epoch 174/1000, accuracy = 0.703,avg_train_cost = 0.017, lastbatch_err = 1.920, time = 11.928,lr=0.00100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7EN_4kwDh08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python ./main.py --infer_dir=/content/AI4Good---Meza-OCR-Challenge/cell_images/validation_set/ \\\n",
        "  --checkpoint_dir=./checkpoint/ \\\n",
        "  --num_gpus=0 \\\n",
        "  --batch_size=29 \\\n",
        "  --mode=infer"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}